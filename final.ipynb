{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import cvxopt\n",
    "from sklearn.svm import SVC\n",
    "from scipy.spatial.distance import cdist\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularized linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression():\n",
    "    def __init__(self, ld=0):\n",
    "        self.ld = ld\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        M, N = X.shape\n",
    "        self.w = np.linalg.inv(X.T @ X + self.ld * np.eye(N)) @ (X.T) @ y\n",
    "        \n",
    "    def predict(self, X):\n",
    "        pred = X @ self.w\n",
    "        return pred.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error(y_true, y_pred):\n",
    "    mul = y_true * y_pred\n",
    "    return np.sum(mul < 0) / len(y_true)\n",
    "\n",
    "def transform(X, funcs, keep_cols=True):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    - X: input nd-array\n",
    "    - funcs: a list of functions applied on input's columns\n",
    "    \n",
    "    Return: a new input matrix with new features\n",
    "    \"\"\"\n",
    "    \n",
    "    for f in funcs:\n",
    "        newcol = f(X).reshape(-1,1)\n",
    "        X = np.hstack((X, newcol))\n",
    "    if not keep_cols:\n",
    "        X = X[:, X.shape[1]-len(funcs):]\n",
    "    return X\n",
    "\n",
    "def one_vs_one(X, y, a, b):\n",
    "    y_reduced = y[(y==a) | (y==b)]\n",
    "    X_reduced = X[(y==a) | (y==b)]\n",
    "    y_cp = y_reduced.copy()\n",
    "    y_cp[y_reduced==a] = 1\n",
    "    y_cp[y_reduced==b] = -1\n",
    "    return X_reduced, y_cp\n",
    "\n",
    "def one_vs_all(y, a):\n",
    "    y_cp = y.copy()\n",
    "    y_cp[y==a] = 1\n",
    "    y_cp[y!=a] = -1\n",
    "    return y_cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_table('datasets/features.train', header=None, sep='  ', engine='python')\n",
    "test_df = pd.read_table('datasets/features.test', header=None, sep='  ', engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7291, 3) (2007, 3)\n"
     ]
    }
   ],
   "source": [
    "print(train_df.shape, test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.iloc[:, 1:]\n",
    "y_train = train_df.iloc[:, 0]\n",
    "\n",
    "X_test = test_df.iloc[:, 1:]\n",
    "y_test = test_df.iloc[:, 0]\n",
    "\n",
    "X_train = np.hstack((np.ones((len(X_train),1)), X_train))\n",
    "X_test = np.hstack((np.ones((len(X_test),1)), X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-vs-all classifier: Ein = 0.0763\n",
      "6-vs-all classifier: Ein = 0.0911\n",
      "7-vs-all classifier: Ein = 0.0885\n",
      "8-vs-all classifier: Ein = 0.0743\n",
      "9-vs-all classifier: Ein = 0.0883\n"
     ]
    }
   ],
   "source": [
    "for k in [5, 6, 7, 8, 9]:\n",
    "    y_train_tmp = one_vs_all(y_train, k)\n",
    "    lr = LinearRegression(ld=1)\n",
    "    lr.fit(X_train, y_train_tmp)\n",
    "    pred = lr.predict(X_train)\n",
    "    Ein = error(y_train_tmp, pred)\n",
    "    print('{}-vs-all classifier: Ein = {:.4f}'.format(k, Ein))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-vs-all classifier: Eout = 0.1066\n",
      "1-vs-all classifier: Eout = 0.0219\n",
      "2-vs-all classifier: Eout = 0.0987\n",
      "3-vs-all classifier: Eout = 0.0827\n",
      "4-vs-all classifier: Eout = 0.0997\n"
     ]
    }
   ],
   "source": [
    "nonlinear_trans = [lambda x: x[:,1]*x[:,2],\n",
    "                  lambda x: x[:,1]**2,\n",
    "                  lambda x: x[:,2]**2]\n",
    "\n",
    "for k in range(5):\n",
    "    X_train_tmp = transform(X_train, nonlinear_trans)\n",
    "    y_train_tmp = one_vs_all(y_train, k)\n",
    "    X_test_tmp = transform(X_test, nonlinear_trans)\n",
    "    y_test_tmp = one_vs_all(y_test, k)\n",
    "    lr = LinearRegression(ld=1)\n",
    "    lr.fit(X_train_tmp, y_train_tmp)\n",
    "    pred_test = lr.predict(X_test_tmp)\n",
    "    Eout = error(y_test_tmp, pred_test)\n",
    "    print('{}-vs-all classifier: Eout = {:.4f}'.format(k, Eout))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* 0-vs-all classifier:\n",
      "\t- without transformation: Ein = 0.1093, Eout = 0.1151\n",
      "\t- with transformation: Ein = 0.1023, Eout = 0.1066\n",
      "\t- Improvement for Eout: Eout (transformed)/Eout (nontransformed) = 0.926\n",
      "\n",
      "* 1-vs-all classifier:\n",
      "\t- without transformation: Ein = 0.0152, Eout = 0.0224\n",
      "\t- with transformation: Ein = 0.0123, Eout = 0.0219\n",
      "\t- Improvement for Eout: Eout (transformed)/Eout (nontransformed) = 0.978\n",
      "\n",
      "* 2-vs-all classifier:\n",
      "\t- without transformation: Ein = 0.1003, Eout = 0.0987\n",
      "\t- with transformation: Ein = 0.1003, Eout = 0.0987\n",
      "\t- Improvement for Eout: Eout (transformed)/Eout (nontransformed) = 1.000\n",
      "\n",
      "* 3-vs-all classifier:\n",
      "\t- without transformation: Ein = 0.0902, Eout = 0.0827\n",
      "\t- with transformation: Ein = 0.0902, Eout = 0.0827\n",
      "\t- Improvement for Eout: Eout (transformed)/Eout (nontransformed) = 1.000\n",
      "\n",
      "* 4-vs-all classifier:\n",
      "\t- without transformation: Ein = 0.0894, Eout = 0.0997\n",
      "\t- with transformation: Ein = 0.0894, Eout = 0.0997\n",
      "\t- Improvement for Eout: Eout (transformed)/Eout (nontransformed) = 1.000\n",
      "\n",
      "* 5-vs-all classifier:\n",
      "\t- without transformation: Ein = 0.0763, Eout = 0.0797\n",
      "\t- with transformation: Ein = 0.0763, Eout = 0.0792\n",
      "\t- Improvement for Eout: Eout (transformed)/Eout (nontransformed) = 0.994\n",
      "\n",
      "* 6-vs-all classifier:\n",
      "\t- without transformation: Ein = 0.0911, Eout = 0.0847\n",
      "\t- with transformation: Ein = 0.0911, Eout = 0.0847\n",
      "\t- Improvement for Eout: Eout (transformed)/Eout (nontransformed) = 1.000\n",
      "\n",
      "* 7-vs-all classifier:\n",
      "\t- without transformation: Ein = 0.0885, Eout = 0.0732\n",
      "\t- with transformation: Ein = 0.0885, Eout = 0.0732\n",
      "\t- Improvement for Eout: Eout (transformed)/Eout (nontransformed) = 1.000\n",
      "\n",
      "* 8-vs-all classifier:\n",
      "\t- without transformation: Ein = 0.0743, Eout = 0.0827\n",
      "\t- with transformation: Ein = 0.0743, Eout = 0.0827\n",
      "\t- Improvement for Eout: Eout (transformed)/Eout (nontransformed) = 1.000\n",
      "\n",
      "* 9-vs-all classifier:\n",
      "\t- without transformation: Ein = 0.0883, Eout = 0.0882\n",
      "\t- with transformation: Ein = 0.0883, Eout = 0.0882\n",
      "\t- Improvement for Eout: Eout (transformed)/Eout (nontransformed) = 1.000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k in range(10):\n",
    "    X_train_trans = transform(X_train, nonlinear_trans)\n",
    "    X_test_trans = transform(X_test, nonlinear_trans)\n",
    "    y_train_tmp = one_vs_all(y_train, k)\n",
    "    y_test_tmp = one_vs_all(y_test, k)\n",
    "    \n",
    "    \n",
    "    lr_nontrans = LinearRegression(ld=1)\n",
    "    lr_nontrans.fit(X_train, y_train_tmp)\n",
    "    pred_train_nontrans = lr_nontrans.predict(X_train)\n",
    "    pred_test_nontrans = lr_nontrans.predict(X_test)\n",
    "    Ein_nontrans = error(y_train_tmp, pred_train_nontrans)\n",
    "    Eout_nontrans = error(y_test_tmp, pred_test_nontrans)\n",
    "    \n",
    "    lr_trans = LinearRegression(ld=1)\n",
    "    lr_trans.fit(X_train_trans, y_train_tmp)\n",
    "    pred_train_trans = lr_trans.predict(X_train_trans)\n",
    "    pred_test_trans = lr_trans.predict(X_test_trans)\n",
    "    Ein_trans = error(y_train_tmp, pred_train_trans)\n",
    "    Eout_trans = error(y_test_tmp, pred_test_trans)\n",
    "    \n",
    "    print('* {}-vs-all classifier:'.format(k))\n",
    "    print('\\t- without transformation: Ein = {:.4f}, Eout = {:.4f}'.format(Ein_nontrans, Eout_nontrans))\n",
    "    print('\\t- with transformation: Ein = {:.4f}, Eout = {:.4f}'.format(Ein_trans, Eout_trans))\n",
    "    print('\\t- Improvement for Eout: Eout (transformed)/Eout (nontransformed) = {:.3f}\\n'.format(Eout_trans/Eout_nontrans))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lambda = 0.01: Ein = 0.0045, Eout = 0.0283\n",
      "Lambda = 1: Ein = 0.0051, Eout = 0.0259\n"
     ]
    }
   ],
   "source": [
    "X_train_tmp = transform(X_train, nonlinear_trans)\n",
    "X_test_tmp = transform(X_test, nonlinear_trans)\n",
    "X_train_tmp, y_train_tmp = one_vs_one(X_train_tmp, y_train, 1, 5)\n",
    "X_test_tmp, y_test_tmp = one_vs_one(X_test_tmp, y_test, 1, 5)\n",
    "\n",
    "for ld in [.01, 1]:\n",
    "    lr = LinearRegression(ld)\n",
    "    lr.fit(X_train_tmp, y_train_tmp)\n",
    "    pred_train = lr.predict(X_train_tmp)\n",
    "    pred_test = lr.predict(X_test_tmp)\n",
    "    Ein = error(y_train_tmp, pred_train)\n",
    "    Eout = error(y_test_tmp, pred_test)\n",
    "    print('Lambda = {}: Ein = {:.4f}, Eout = {:.4f}'.format(ld, Ein, Eout))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support vector machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[1, 0],\n",
    "             [0, 1],\n",
    "             [0, -1],\n",
    "             [-1, 0],\n",
    "             [0, 2],\n",
    "             [0, -2],\n",
    "             [-2, 0]])\n",
    "\n",
    "y = np.array([-1, -1, -1, 1, 1, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = transform(X, [lambda x: x[:,1]**2 - 2*x[:,0] - 1, lambda x: x[:,0]**2 - 2*x[:,1] + 1], keep_cols=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(Z[y==-1,0], Z[y==-1,1], 'bo', markersize=10, label='class -1')\n",
    "plt.plot(Z[y==1,0], Z[y==1,1], 'ro', markersize=10, label='class 1')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVM():\n",
    "    def __init__(self, kernel='linear', degree=1, gamma=1):\n",
    "        self.kernel = kernel\n",
    "        self.degree = degree\n",
    "        self.gamma = gamma\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.X = X\n",
    "        if self.kernel == 'linear':\n",
    "            K = X @ X.T\n",
    "        elif self.kernel == 'poly':\n",
    "            K = (1 + X @ X.T)**self.degree\n",
    "        elif self.kernel == 'rbf':\n",
    "            K = np.ndarray((X.shape[0], X.shape[0]))\n",
    "            for i in range(X.shape[0]):\n",
    "                for j in range(X.shape[0]):\n",
    "                    K[i, j] = np.exp(-self.gamma * np.linalg.norm(X[i] - X[j])**2)\n",
    "                    \n",
    "        cvxopt.solvers.options['show_progress'] = False\n",
    "        y = y.reshape(-1,1)\n",
    "        P = (y @ y.T) * K\n",
    "        q = -np.ones(len(y))\n",
    "        G = -np.eye(len(y))\n",
    "        h = np.zeros((len(y),1))\n",
    "        A = y.T\n",
    "        b = np.zeros(1)\n",
    "\n",
    "        P = cvxopt.matrix(P, tc='d')\n",
    "        q = cvxopt.matrix(q, tc='d')\n",
    "        G = cvxopt.matrix(G, tc='d')\n",
    "        h = cvxopt.matrix(h, tc='d')\n",
    "        A = cvxopt.matrix(A, tc='d')\n",
    "        b = cvxopt.matrix(b, tc='d')\n",
    "        cvx = cvxopt.solvers.qp(P, q, G, h, A, b)\n",
    "        self.alpha = np.around(np.array(cvx['x']), decimals = 5)\n",
    "        self.w = (y * K).T @ self.alpha\n",
    "        self.sv_idx = [i for i in range(len(self.alpha)) if self.alpha[i] > 0]\n",
    "        if len(self.sv_idx) == 0:\n",
    "            self.sv_idx.append(0)\n",
    "\n",
    "        # KKT condition\n",
    "        self.b = y[self.sv_idx[0]] - np.sum(self.alpha[:,0] * y[:,0] * K[:, self.sv_idx[0]])\n",
    "        self.y = y\n",
    "    def predict(self, X):\n",
    "        if self.kernel == 'linear':\n",
    "            K = X @ self.X.T\n",
    "        elif self.kernel == 'poly':\n",
    "            K = (1 + X @ self.X.T)**self.degree\n",
    "        elif self.kernel == 'rbf':\n",
    "            K = np.ndarray((X.shape[0], self.X.shape[0]))\n",
    "            for i in range(X.shape[0]):\n",
    "                for j in range(self.X.shape[0]):\n",
    "                    K[i, j] = np.exp(-self.gamma * np.linalg.norm(X[i] - self.X[j])**2)\n",
    "                    \n",
    "        \n",
    "        return np.sign(K @ (self.y[:,0]*self.alpha[:,0]).reshape(-1,1)  + self.b).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of support vectors: 5\n"
     ]
    }
   ],
   "source": [
    "X = np.array([[1, 0],\n",
    "             [0, 1],\n",
    "             [0, -1],\n",
    "             [-1, 0], \n",
    "             [0, 2],\n",
    "             [0, -2],\n",
    "             [-2, 0]])\n",
    "\n",
    "y = np.array([-1, -1, -1, 1, 1, 1, 1])\n",
    "svm = SVM('poly', 2)\n",
    "svm.fit(X, y)\n",
    "print('Number of support vectors: {}'.format(np.sum(svm.alpha>0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Radial basis function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(n_points=100):\n",
    "    X = np.random.uniform(-1, 1, (n_points, 2))\n",
    "    f = np.sign(X[:,1] - X[:,0] + .25*np.sin(np.pi*X[:,0]))\n",
    "    return X, f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 1000 times...\n",
      "Execution finished, time = 224.872s\n",
      "Percentage of times data is not separable by RBF kernel: 0.10%\n"
     ]
    }
   ],
   "source": [
    "n_runs = 1000\n",
    "print('Running {} times...'.format(n_runs))\n",
    "gamma = 1.5\n",
    "notseparable_count = 0\n",
    "start = time.time()\n",
    "for n in range(n_runs):\n",
    "    X, f = generate_data(100)\n",
    "    svm = SVM(kernel='rbf', gamma=gamma)\n",
    "    svm.fit(X, f)\n",
    "    pred = svm.predict(X)\n",
    "    if error(f, pred) > 0:\n",
    "        notseparable_count += 1\n",
    "print('Execution finished, time = {:.3f}s'.format(time.time() - start)       ) \n",
    "print('Percentage of times data is not separable by RBF kernel: {:.2f}%'.format(notseparable_count/n_runs*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegularRBF():\n",
    "    def __init__(self, n_clusters=3, gamma=1):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.gamma = gamma\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.X = X\n",
    "        self.centers = self.init_centers()\n",
    "        self.get_cluster()\n",
    "        self.KMeans()\n",
    "        self.phi = np.exp(-self.gamma * cdist(self.X, self.centers)**2)\n",
    "        self.phi = np.hstack((np.ones((self.X.shape[0],1)), self.phi))\n",
    "        self.w = np.linalg.inv(self.phi.T @ self.phi) @ self.phi.T @ y\n",
    "        \n",
    "    def init_centers(self):\n",
    "        self.clusters = np.zeros(len(self.X))\n",
    "        C = np.random.uniform(-1.,1., size=(self.n_clusters, X.shape[1]))\n",
    "        return C\n",
    "    \n",
    "    def get_cluster(self):\n",
    "        for i in range(len(self.X)):\n",
    "            self.clusters[i] = np.argmin(cdist(X[i,None], self.centers))\n",
    "            \n",
    "    def KMeans(self):\n",
    "        self.converged = False\n",
    "        self.iter_kmeans = 0\n",
    "        while not self.converged:\n",
    "            self.iter_kmeans += 1\n",
    "            if self.iter_kmeans >= 100:\n",
    "                self.centers = self.init_centers()\n",
    "                self.get_cluster()\n",
    "                self.iter_kmeans = 0\n",
    "                continue\n",
    "            prev_centers = self.centers.copy()\n",
    "            for k in range(self.n_clusters):\n",
    "                self.centers[k] = np.mean(X[self.clusters==k, :], axis=0)\n",
    "            self.get_cluster()\n",
    "            if np.array_equal(prev_centers, self.centers):\n",
    "                self.converged = True\n",
    "                for i in range(self.n_clusters):\n",
    "                    n_ci = np.sum(self.clusters == i)\n",
    "                    if n_ci == 0:\n",
    "                        self.centers = self.init_centers()\n",
    "                        self.get_cluster()\n",
    "                        self.iter_kmeans = 0\n",
    "                        self.converged = False\n",
    "                        continue\n",
    "                \n",
    "                \n",
    "    def predict(self, X):\n",
    "        phi = np.exp(-self.gamma * cdist(X, self.centers)**2)\n",
    "        phi = np.hstack((np.ones((X.shape[0],1)), phi))\n",
    "        return np.sign(phi @ self.w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 1000 times...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tungo/opt/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/Users/tungo/opt/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py:154: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret, rcount, out=ret, casting='unsafe', subok=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution finished, time = 271.043s\n",
      "Percentage of times kernel form beats regular form: 71.60%\n"
     ]
    }
   ],
   "source": [
    "n_runs = 1000\n",
    "print('Running {} times...'.format(n_runs))\n",
    "gamma = 1.5\n",
    "K = 9\n",
    "kernelbeat_cnt = 0\n",
    "cnt = 0\n",
    "start = time.time()\n",
    "for n in range(n_runs):\n",
    "    X_train, y_train = generate_data(100)\n",
    "    X_test, y_test = generate_data(100)\n",
    "    \n",
    "    svm = SVM(kernel='rbf', gamma=gamma)\n",
    "    svm.fit(X_train, y_train)\n",
    "    regRBF = RegularRBF(n_clusters=K, gamma=gamma)\n",
    "    regRBF.fit(X_train, y_train)\n",
    "    \n",
    "    pred_svm = svm.predict(X_test)\n",
    "    pred_rbf = regRBF.predict(X_test)\n",
    "    if error(y_test, pred_svm) < error(y_test, pred_rbf):\n",
    "        kernelbeat_cnt += 1\n",
    "print('Execution finished, time = {:.3f}s'.format(time.time() - start)) \n",
    "print('Percentage of times kernel form beats regular form: {:.2f}%'.format(kernelbeat_cnt/n_runs*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 1000 times...\n",
      "Execution finished, time = 305.282s\n",
      "Percentage of times kernel form beats regular form: 60.40%\n"
     ]
    }
   ],
   "source": [
    "n_runs = 1000\n",
    "print('Running {} times...'.format(n_runs))\n",
    "gamma = 1.5\n",
    "K = 12\n",
    "kernelbeat_cnt = 0\n",
    "start = time.time()\n",
    "for n in range(n_runs):\n",
    "    X_train, y_train = generate_data(100)\n",
    "    X_test, y_test = generate_data(100)\n",
    "    \n",
    "    svm = SVM(kernel='rbf', gamma=gamma)\n",
    "    svm.fit(X_train, y_train)\n",
    "    regRBF = RegularRBF(n_clusters=K, gamma=gamma)\n",
    "    regRBF.fit(X_train, y_train)\n",
    "    \n",
    "    pred_svm = svm.predict(X_test)\n",
    "    pred_rbf = regRBF.predict(X_test)\n",
    "    if error(y_test, pred_svm) < error(y_test, pred_rbf):\n",
    "        kernelbeat_cnt += 1\n",
    "print('Execution finished, time = {:.3f}s'.format(time.time() - start)) \n",
    "print('Percentage of times kernel form beats regular form: {:.2f}%'.format(kernelbeat_cnt/n_runs*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 1000 times...\n",
      "Execution finished, time = 88.217s\n",
      "\n",
      "- Ein goes up: 0.00%\n",
      "- Ein goes down: 100.00%\n",
      "- Ein keeps the same: 0.00%\n",
      "- Eout goes up: 0.00%\n",
      "- Eout goes down: 100.00%\n",
      "- Eout keeps the same: 0.00%\n"
     ]
    }
   ],
   "source": [
    "n_runs = 1000\n",
    "print('Running {} times...'.format(n_runs))\n",
    "gamma = 1.5\n",
    "K1, K2 = 9, 12\n",
    "Ein_up_cnt, Ein_down_cnt, Ein_same_cnt = 0, 0, 0\n",
    "Eout_up_cnt, Eout_down_cnt, Eout_same_cnt = 0, 0, 0\n",
    "start = time.time()\n",
    "for n in range(n_runs):\n",
    "    X_train, y_train = generate_data(100)\n",
    "    X_test, y_test = generate_data(100)\n",
    "    \n",
    "    rbf1 = RegularRBF(K1, gamma)\n",
    "    rbf1.fit(X_train, y_train)\n",
    "    \n",
    "    rbf2 = RegularRBF(K2, gamma)\n",
    "    rbf2.fit(X_train, y_train)\n",
    "    \n",
    "    pred_train1 = rbf1.predict(X_train)\n",
    "    pred_train2 = rbf2.predict(X_train)\n",
    "    pred_test1 = rbf1.predict(X_test)\n",
    "    pred_test2 = rbf2.predict(X_test)\n",
    "    \n",
    "    Ein1 = error(y_train, pred_train1)\n",
    "    Ein2 = error(y_train, pred_train2)\n",
    "    Eout1 = error(y_test, pred_test1)\n",
    "    Eout2 = error(y_test, pred_test2)\n",
    "    \n",
    "    if Ein2 > Ein1:\n",
    "        Ein_up_cnt +=1\n",
    "    elif Ein2 == Ein1:\n",
    "        Ein_same_cnt += 1\n",
    "    else:\n",
    "        Ein_down_cnt += 1\n",
    "        \n",
    "    if Eout2 > Eout1:\n",
    "        Eout_up_cnt +=1\n",
    "    elif Eout2 == Eout1:\n",
    "        Eout_same_cnt += 1\n",
    "    else:\n",
    "        Eout_down_cnt += 1\n",
    "print('Execution finished, time = {:.3f}s'.format(time.time() - start))\n",
    "print()\n",
    "print('- Ein goes up: {:.2f}%'.format(Ein_up_cnt/n_runs*100))\n",
    "print('- Ein goes down: {:.2f}%'.format(Ein_down_cnt/n_runs*100))\n",
    "print('- Ein keeps the same: {:.2f}%'.format(Ein_same_cnt/n_runs*100))\n",
    "print('- Eout goes up: {:.2f}%'.format(Eout_up_cnt/n_runs*100))\n",
    "print('- Eout goes down: {:.2f}%'.format(Eout_down_cnt/n_runs*100))\n",
    "print('- Eout keeps the same: {:.2f}%'.format(Eout_same_cnt/n_runs*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 1000 times...\n",
      "Execution finished, time = 78.327s\n",
      "\n",
      "- Ein goes up: 45.80%\n",
      "- Ein goes down: 31.30%\n",
      "- Ein keeps the same: 22.90%\n",
      "- Eout goes up: 42.80%\n",
      "- Eout goes down: 39.60%\n",
      "- Eout keeps the same: 17.60%\n"
     ]
    }
   ],
   "source": [
    "n_runs = 1000\n",
    "print('Running {} times...'.format(n_runs))\n",
    "gamma1, gamma2 = 1.5, 2\n",
    "K = 9\n",
    "Ein_up_cnt, Ein_down_cnt, Ein_same_cnt = 0, 0, 0\n",
    "Eout_up_cnt, Eout_down_cnt, Eout_same_cnt = 0, 0, 0\n",
    "start = time.time()\n",
    "for n in range(n_runs):\n",
    "    X_train, y_train = generate_data(100)\n",
    "    X_test, y_test = generate_data(100)\n",
    "    \n",
    "    rbf1 = RegularRBF(K, gamma1)\n",
    "    rbf1.fit(X_train, y_train)\n",
    "    \n",
    "    rbf2 = RegularRBF(K, gamma2)\n",
    "    rbf2.fit(X_train, y_train)\n",
    "    \n",
    "    pred_train1 = rbf1.predict(X_train)\n",
    "    pred_train2 = rbf2.predict(X_train)\n",
    "    pred_test1 = rbf1.predict(X_test)\n",
    "    pred_test2 = rbf2.predict(X_test)\n",
    "    \n",
    "    Ein1 = error(y_train, pred_train1)\n",
    "    Ein2 = error(y_train, pred_train2)\n",
    "    Eout1 = error(y_test, pred_test1)\n",
    "    Eout2 = error(y_test, pred_test2)\n",
    "    \n",
    "    if Ein2 > Ein1:\n",
    "        Ein_up_cnt +=1\n",
    "    elif Ein2 == Ein1:\n",
    "        Ein_same_cnt += 1\n",
    "    else:\n",
    "        Ein_down_cnt += 1\n",
    "        \n",
    "    if Eout2 > Eout1:\n",
    "        Eout_up_cnt +=1\n",
    "    elif Eout2 == Eout1:\n",
    "        Eout_same_cnt += 1\n",
    "    else:\n",
    "        Eout_down_cnt += 1\n",
    "print('Execution finished, time = {:.3f}s'.format(time.time() - start))\n",
    "print()\n",
    "print('- Ein goes up: {:.2f}%'.format(Ein_up_cnt/n_runs*100))\n",
    "print('- Ein goes down: {:.2f}%'.format(Ein_down_cnt/n_runs*100))\n",
    "print('- Ein keeps the same: {:.2f}%'.format(Ein_same_cnt/n_runs*100))\n",
    "print('- Eout goes up: {:.2f}%'.format(Eout_up_cnt/n_runs*100))\n",
    "print('- Eout goes down: {:.2f}%'.format(Eout_down_cnt/n_runs*100))\n",
    "print('- Eout keeps the same: {:.2f}%'.format(Eout_same_cnt/n_runs*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 1000 times...\n",
      "Execution finished, time = 45.125s\n",
      "Percentage of times Ein=0: 4.40%\n"
     ]
    }
   ],
   "source": [
    "n_runs = 1000\n",
    "print('Running {} times...'.format(n_runs))\n",
    "gamma = 1.5\n",
    "K = 9\n",
    "perfect_cnt = 0\n",
    "start = time.time()\n",
    "for n in range(n_runs):\n",
    "    X_train, y_train = generate_data(100)\n",
    "    \n",
    "    regRBF = RegularRBF(n_clusters=K, gamma=gamma)\n",
    "    regRBF.fit(X_train, y_train)\n",
    "    \n",
    "    pred = regRBF.predict(X_train)\n",
    "    if error(y_train, pred) == 0:\n",
    "        perfect_cnt += 1\n",
    "print('Execution finished, time = {:.3f}s'.format(time.time() - start)) \n",
    "print('Percentage of times Ein=0: {:.2f}%'.format(perfect_cnt/n_runs*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
